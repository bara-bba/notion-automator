{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NOTION_MONEY_TRANSACTIONS'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabula\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m DB_TRANSACTIONS = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNOTION_MONEY_TRANSACTIONS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Replace with your database ID\u001b[39;00m\n\u001b[32m      9\u001b[39m DB_CSV = os.environ[\u001b[33m'\u001b[39m\u001b[33mNOTION_MONEY_CSV\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# Replace with your database ID\u001b[39;00m\n\u001b[32m     10\u001b[39m NOTION_API_KEY = os.environ[\u001b[33m'\u001b[39m\u001b[33mNOTION_TOKEN\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# Replace with your database ID\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:716\u001b[39m, in \u001b[36m__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'NOTION_MONEY_TRANSACTIONS'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import tabula\n",
    "\n",
    "\n",
    "DB_TRANSACTIONS = os.environ['NOTION_MONEY_TRANSACTIONS']  # Replace with your database ID\n",
    "DB_CSV = os.environ['NOTION_MONEY_CSV']  # Replace with your database ID\n",
    "NOTION_API_KEY = os.environ['NOTION_TOKEN']  # Replace with your database ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notion_client import Client\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \" + NOTION_API_KEY,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Notion-Version\": \"2022-06-28\",\n",
    "}\n",
    "\n",
    "def get_pages(num_pages=None):\n",
    "    \"\"\"\n",
    "    If num_pages is None, get all pages, otherwise just the defined number.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.notion.com/v1/databases/{DB_CSV}/query\"\n",
    "\n",
    "    get_all = num_pages is None\n",
    "    page_size = 100 if get_all else num_pages\n",
    "\n",
    "    filter = {\n",
    "        \"filter\": {\n",
    "            \"property\": \"Added\",\n",
    "            \"checkbox\": {\n",
    "            \"equals\": False\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    response = requests.post(url, json=filter, headers=headers)\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    results = data[\"results\"]\n",
    "    while data[\"has_more\"] and get_all:\n",
    "        payload = {\"page_size\": page_size, \"start_cursor\": data[\"next_cursor\"]}\n",
    "        url = f\"https://api.notion.com/v1/databases/{DB_CSV}/query\"\n",
    "        response = requests.post(url, json=filter, headers=headers)\n",
    "        data = response.json()\n",
    "        results.extend(data[\"results\"])\n",
    "\n",
    "    return results\n",
    "\n",
    "notion = Client(auth=NOTION_API_KEY)\n",
    "list_users_response = notion.users.list()\n",
    "\n",
    "results = get_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n26 = []\n",
    "list_buddy = []\n",
    "\n",
    "for item in results:\n",
    "    # url = item[\"properties\"][\"CSV\"][\"files\"][0][\"file\"][\"url\"]\n",
    "    try:\n",
    "        if item[\"properties\"][\"Name\"][\"title\"][0][\"text\"][\"content\"].find(\"Buddy\") != -1:\n",
    "            list_buddy.append(\n",
    "                {   \n",
    "                    \"id\": item[\"id\"],\n",
    "                    \"url\": item[\"properties\"][\"CSV\"][\"files\"][0][\"file\"][\"url\"]\n",
    "                }\n",
    "            )\n",
    "        elif item[\"properties\"][\"Name\"][\"title\"][0][\"text\"][\"content\"].find(\"N26\") != -1:\n",
    "            list_n26.append(\n",
    "                {   \n",
    "                    \"id\": item[\"id\"],\n",
    "                    \"url\": item[\"properties\"][\"CSV\"][\"files\"][0][\"file\"][\"url\"]\n",
    "                }\n",
    "            )\n",
    "    except:\n",
    "        print(\"No File Attached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item(title, description='', date='', account ='', amount='', category=''):\n",
    "    if not category:\n",
    "        category = 'Other'\n",
    "    if description == 'nan':\n",
    "        description = ''\n",
    "    url = f'https://api.notion.com/v1/pages'\n",
    "    # Prepare the payload for the new task\n",
    "    payload = {\n",
    "        'parent': {\n",
    "            'database_id': f'{DB_TRANSACTIONS}'\n",
    "        },\n",
    "        \n",
    "        'properties': {\n",
    "            'Name': {\n",
    "                'title': [{\n",
    "                    'text': {\n",
    "                        'content': title\n",
    "                    }\n",
    "                }]\n",
    "            },\n",
    "            'Description': {\n",
    "                'rich_text': [{\n",
    "                    'text': {\n",
    "                        'content': str(description)\n",
    "                    }\n",
    "                }]\n",
    "            },\n",
    "            'Transaction Date': {\n",
    "                'date': {\n",
    "                    'start': date\n",
    "                }\n",
    "            },\n",
    "            'Account': {\n",
    "                'select': {\n",
    "                    'name': account\n",
    "                }\n",
    "            },\n",
    "            'Price': {\n",
    "                'number': float(amount)\n",
    "            },\n",
    "            'Category': {\n",
    "                \"select\": {\n",
    "                    \"name\": category\n",
    "                    },\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Task '{title}' created successfully.\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(f\"Error creating task: {response.status_code} {response.text}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buddybank.pdf\n",
    "Tested on Q2 24 with big number of element.\n",
    "\n",
    "### FD\n",
    "Add partial sum verification as for Buddybank Lite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buddy_to_notion(df):\n",
    "    try:\n",
    "        df[\"Entrate\"] = (df['Entrate'].str.replace('.', '').str.replace(',', '.').astype(float))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df[\"Uscite\"] = (df['Uscite'].str.replace('.', '').str.replace(',', '.').astype(float))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        val_date_str = row[\"Valuta\"]\n",
    "\n",
    "        try:\n",
    "            val_date = datetime.strptime(val_date_str, \"%Y-%m-%d\")\n",
    "        except:\n",
    "            try:\n",
    "                val_date = datetime.strptime(val_date_str, \"%d.%m.%y\")\n",
    "            except:\n",
    "                print(f\"Row is not a valid one, shit\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            title = row[\"Descrizione\"].split(\"*\")[2]\n",
    "        except:\n",
    "            title = row[\"Descrizione\"]\n",
    "\n",
    "        account = \"Buddybank\"\n",
    "        \n",
    "        if not np.isnan(row[\"Entrate\"]): \n",
    "            amount = row[\"Entrate\"]\n",
    "        else: \n",
    "            amount = - abs(row[\"Uscite\"])\n",
    "        \n",
    "        create_item(title=title,\n",
    "                    date=val_date.strftime(\"%Y-%m-%d\"),\n",
    "                    account=account,\n",
    "                    amount=amount)\n",
    "    else:\n",
    "            print(\"Execution Complete\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for list_item in list_buddy:\n",
    "    try: \n",
    "        tables = tabula.read_pdf(list_item[\"url\"], pages=\"all\", multiple_tables=True, lattice=True)\n",
    "        df_temp = pd.concat(tables)\n",
    "\n",
    "        df_temp = df_temp[1:] #take the data less the header row\n",
    "        # df_temp.columns = new_header #set the header row as the df header\n",
    "        df_temp = df_temp[df_temp.Valuta != 'Valuta']\n",
    "        df_temp.dropna(how='all', axis=0, inplace=True)\n",
    "        df_temp.dropna(how='all', axis=1, inplace=True)\n",
    "        df_temp = df_temp[1:] #take the data less the header row\n",
    "        df_temp = df_temp[:-2].reindex()\n",
    "\n",
    "        for index, item in df_temp.iterrows():\n",
    "            if item[\"Descrizione\"].find(\"EUR\") != -1:\n",
    "                item[\"Descrizione\"] = item[\"Descrizione\"][(item[\"Descrizione\"].find(\"EUR\"))+9:].strip()\n",
    "                print(item[\"Descrizione\"].strip())\n",
    "            elif item[\"Descrizione\"].find(\"AUD\") != -1:\n",
    "                item[\"Descrizione\"] = item[\"Descrizione\"][(item[\"Descrizione\"].find(\"AUD\"))+9:].strip()\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        buddy_to_notion(df_temp)\n",
    "    except:\n",
    "        print(f\"Error with {item}\")\n",
    "        print(\"no\")\n",
    "    else:\n",
    "        notion.pages.update(\n",
    "            list_item[\"id\"],\n",
    "            properties={\n",
    "                \"Added\": {\n",
    "                    \"checkbox\": True\n",
    "                }\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N26.pdf\n",
    "Last run in Sept 2024. Verify after usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "\n",
    "def N26_to_notion(df):\n",
    "    \n",
    "    for index, rows in df.iterrows():\n",
    "        date_str = rows[\"Booking Date\"]\n",
    "        date = datetime.strptime(date_str, \"%d.%m.%Y\")\n",
    "        if not create_item( title=f'{rows[\"Description\"]}',\n",
    "                            date=f'{date.strftime(\"%Y-%m-%d\")}',\n",
    "                            account=f'{\"N26\"}',\n",
    "                            amount=f'{rows[\"Amount\"]}',\n",
    "                            description='',\n",
    "                            category='Other'):\n",
    "            print(\"Error in execution, correct the configuration and start again\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Execution Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Description', 'Booking Date', 'Amount']\n",
    "\n",
    "for list_item in list_n26:\n",
    "    try: \n",
    "        tables = tabula.read_pdf(list_item[\"url\"], pages=\"all\", multiple_tables=False, lattice=False)\n",
    "\n",
    "        df_temp = tables[0]\n",
    "        df_temp = pd.DataFrame(df_temp.values[0:], columns=header)\n",
    "        restore_row = tables[0].columns.to_list()\n",
    "        df_temp = pd.concat([df_temp, pd.DataFrame([tables[0].columns.to_list()], columns=header)], ignore_index=True, axis=0) # does not save changes to the original dataframe\n",
    "        df_temp[\"Amount\"] = df_temp[\"Amount\"].str.replace('€','').str.replace('.','').str.replace(',','.').astype(float)\n",
    "        df_temp = df_temp[df_temp['Amount'].notna()]\n",
    "        \n",
    "        N26_to_notion(df_temp)\n",
    "        \n",
    "    except:\n",
    "        print(\"Brutta madonna\")\n",
    "    else:\n",
    "        notion.pages.update(\n",
    "            item[\"id\"],\n",
    "            properties={\n",
    "                \"Added\": {\n",
    "                    \"checkbox\": True\n",
    "                }\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = tabula.read_pdf(list_item[\"url\"], pages=\"all\", multiple_tables=False, lattice=False)\n",
    "\n",
    "df_temp = tables[0]\n",
    "df_temp = pd.DataFrame(df_temp.values[0:], columns=header)\n",
    "restore_row = tables[0].columns.to_list()\n",
    "df_temp = pd.concat([df_temp, pd.DataFrame([tables[0].columns.to_list()], columns=header)], ignore_index=True, axis=0) # does not save changes to the original dataframe\n",
    "df_temp[\"Amount\"] = df_temp[\"Amount\"].str.replace('€','').str.replace('.','').str.replace(',','.').astype(float)\n",
    "df_temp = df_temp[df_temp['Amount'].notna()]\n",
    "\n",
    "N26_to_notion(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BuddybankMonthly.pdf (Lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trovati 1 file PDF contenenti 'Buddy' e 'Lite':\n",
      "  - BuddybankLite_October.pdf\n",
      "\n",
      "Inizio elaborazione...\n",
      "\n",
      "======================================================================\n",
      "FILE: BuddybankLite_October.pdf\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_2744\\4136249107.py:163: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = pd.concat([df_temp, pd.DataFrame([new_df_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVVISO: somma parziale diversa dal totale indicato.\n",
      "  Parziale: 1218.87\n",
      "  Totale  : 460.42\n",
      "Transazioni estratte: 569\n",
      "File CSV generato: C:\\Users\\loren\\OneDrive\\Desktop\\Areas\\Finanza\\BuddybankLite_October.csv\n",
      "======================================================================\n",
      "\n",
      "Elaborazione completata.\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2025\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# === Funzione per pulire la descrizione ===\n",
    "def pulisci_descrizione(testo):\n",
    "    if not isinstance(testo, str):\n",
    "        return \"\"\n",
    "\n",
    "    testo = testo.strip()\n",
    "\n",
    "    # Bonifico in entrata: \"BONIFICO A VOSTRO FAVORE ... DA:\"\n",
    "    if \"BONIFICO A VOSTRO FAVORE\" in testo.upper() and \"DA:\" in testo.upper():\n",
    "        m = re.search(r\"DA:\\s*([^,]+)\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(1).strip()\n",
    "\n",
    "    # Bonifico in uscita: \"BONIFICO SEPA A:\"\n",
    "    if \"BONIFICO SEPA A:\" in testo.upper():\n",
    "        m = re.search(r\"A:\\s*([^P]+)\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(1).strip()\n",
    "\n",
    "    # Pagamenti con carta, contactless, Apple Pay, ecc.\n",
    "    if \"PAGAMENTO\" in testo.upper():\n",
    "        m = re.search(r\"EUR [\\d,.]+\\s*(.*)\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            beneficiario = m.group(1)\n",
    "            beneficiario = re.sub(r\"\\b\\d+\\b\", \"\", beneficiario)  # rimuove numeri\n",
    "            beneficiario = re.sub(r\"\\s{2,}\", \" \", beneficiario)   # rimuove spazi doppi\n",
    "            return beneficiario.strip()\n",
    "\n",
    "    # Addebiti SEPA o PayPal\n",
    "    if \"SEPA\" in testo.upper() or \"PAYPAL\" in testo.upper():\n",
    "        m = re.search(r\"PayPal[^\\s,]*\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(0).strip()\n",
    "        m = re.search(r\"da\\s+([A-Za-z\\s\\.&]+)\\s+mandato\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(1).strip()\n",
    "\n",
    "    # Fallback: testo pulito senza simboli eccessivi\n",
    "    testo = re.sub(r\"\\s{2,}\", \" \", testo)\n",
    "    return testo.strip()\n",
    "\n",
    "# Dizionario mesi italiani → inglesi\n",
    "it_to_eng_dict = {\n",
    "    \"gennaio\": \"Jan\",\n",
    "    \"febbraio\": \"Feb\",\n",
    "    \"marzo\": \"Mar\",\n",
    "    \"maggio\": \"May\",\n",
    "    \"giugno\": \"Jun\",\n",
    "    \"luglio\": \"Jul\",\n",
    "    \"agosto\": \"Aug\",\n",
    "    \"settembre\": \"Sep\",\n",
    "    \"ottobre\": \"Oct\",\n",
    "    \"novembre\": \"Nov\",\n",
    "    \"dicembre\": \"Dec\"\n",
    "}\n",
    "\n",
    "# Directory contenente i PDF\n",
    "pdf_dir = r\"C:\\Users\\loren\\OneDrive\\Desktop\\Areas\\Finanza\"\n",
    "pdf_files = [\n",
    "    f for f in os.listdir(pdf_dir)\n",
    "    if f.lower().endswith(\".pdf\") and \"buddy\" in f.lower() and \"lite\" in f.lower()\n",
    "]\n",
    "\n",
    "# Regex e funzioni di supporto\n",
    "regex_list = [r\"\\b\\d\\d\\s\", r\"\\b\\d\\s\", r\"\\b\\d\"]\n",
    "\n",
    "def remove_elements_at_indices(test_list, idx_list):\n",
    "    if not idx_list:\n",
    "        return test_list\n",
    "    first_idx = idx_list[0]\n",
    "    rest_of_indices = idx_list[1:]\n",
    "    sub_list = remove_elements_at_indices(test_list, rest_of_indices)\n",
    "    sub_list.pop(first_idx)\n",
    "    return sub_list\n",
    "\n",
    "# Inizio elaborazione\n",
    "print(f\"\\nTrovati {len(pdf_files)} file PDF contenenti 'Buddy' e 'Lite':\")\n",
    "for f in pdf_files:\n",
    "    print(f\"  - {f}\")\n",
    "print(\"\\nInizio elaborazione...\\n\")\n",
    "\n",
    "# Processamento PDF\n",
    "for file_name in pdf_files:\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"FILE: {file_name}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    df_temp = pd.DataFrame(columns=[\"Data\", \"Beneficiario\", \"Importo\"])\n",
    "    file_path = os.path.join(pdf_dir, file_name)\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    page_lines = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        lines = text.splitlines()\n",
    "        page_lines.extend(lines)\n",
    "\n",
    "    # Rimozione numeri di pagina\n",
    "    idx_list = [index for (index, item) in enumerate(page_lines)\n",
    "                if re.match(r\"(?<!\\S)\\d(?!\\S)(?!.)\", item)]\n",
    "    page_lines = remove_elements_at_indices(page_lines, idx_list)\n",
    "\n",
    "    # Individuazione inizio dati\n",
    "    dates_indexes = [index for (index, item) in enumerate(page_lines)\n",
    "                     if re.match(regex_list[0], item) or re.match(regex_list[1], item)]\n",
    "    if not dates_indexes:\n",
    "        print(\"Nessuna data trovata. File saltato.\")\n",
    "        continue\n",
    "\n",
    "    page_lines = page_lines[dates_indexes[0]:]\n",
    "    dates_indexes = [index for (index, item) in enumerate(page_lines)\n",
    "                     if re.match(regex_list[0], item) or re.match(regex_list[1], item)]\n",
    "\n",
    "    buffer = \"\"\n",
    "    skip = False\n",
    "\n",
    "    for index, line in enumerate(page_lines):\n",
    "        if index in dates_indexes:\n",
    "            date = page_lines[index]\n",
    "            continue\n",
    "\n",
    "        if (index < len(page_lines)-1 and page_lines[index] == page_lines[index+1]) or skip:\n",
    "            skip = False\n",
    "            continue\n",
    "\n",
    "        if unicodedata.lookup(\"EURO SIGN\") not in page_lines[index] and (index not in dates_indexes):\n",
    "            buffer += page_lines[index]\n",
    "            continue\n",
    "\n",
    "        if unicodedata.lookup(\"EURO SIGN\") in page_lines[index]:\n",
    "            new_row = buffer + page_lines[index]\n",
    "            buffer = \"\"\n",
    "\n",
    "        try:\n",
    "            money = re.search(r\"(-\\d+\\,?\\d*\\s\\€|\\d+\\,?\\d*\\s\\€)\", new_row)\n",
    "            if not money:\n",
    "                continue\n",
    "\n",
    "            descrizione = new_row[:money.start()]\n",
    "            val_date_str = re.sub(r'\\b' + r'|\\b'.join(it_to_eng_dict) + r'\\b',\n",
    "                                  lambda m: it_to_eng_dict.get(m.group(), m.group()), date)\n",
    "            val_date_str = val_date_str + f\" {YEAR}\"\n",
    "            val_date = datetime.strptime(val_date_str, \"%d %b %Y\")\n",
    "            money_val = float(money.group().replace('€', '').replace('.', '').replace(',', '.'))\n",
    "\n",
    "            if money_val < 0:\n",
    "                new_df_row = {\"Data\": val_date.strftime(\"%m/%d/%Y\"),\n",
    "                              \"Beneficiario\": descrizione, \"Importo\": money_val}\n",
    "            else:\n",
    "                new_df_row = {\"Data\": val_date.strftime(\"%m/%d/%Y\"),\n",
    "                              \"Beneficiario\": descrizione, \"Importo\": money_val}\n",
    "\n",
    "            df_temp = pd.concat([df_temp, pd.DataFrame([new_df_row])], ignore_index=True)\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Verifica somme\n",
    "    df_temp[\"Importo\"] = df_temp[\"Importo\"].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    try:\n",
    "        total_sum = df_temp[\"Importo\"].iloc[-1]\n",
    "        partial_sum = df_temp[\"Importo\"][:-1].sum()\n",
    "        if total_sum != round(partial_sum, 2):\n",
    "            print(\"AVVISO: somma parziale diversa dal totale indicato.\")\n",
    "            print(f\"  Parziale: {partial_sum:.2f}\")\n",
    "            print(f\"  Totale  : {total_sum}\")\n",
    "        else:\n",
    "            print(\"Somme verificate correttamente.\")\n",
    "    except Exception:\n",
    "        print(\"Impossibile verificare le somme (dati non completi).\")\n",
    "\n",
    "    # Pulizia descrizioni\n",
    "    df_temp[\"Beneficiario\"] = df_temp[\"Beneficiario\"].apply(pulisci_descrizione)\n",
    "\n",
    "    # Salvataggio\n",
    "    output_path = os.path.join(pdf_dir, f\"{file_name[:-4]}.csv\")\n",
    "    df_temp.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Transazioni estratte: {len(df_temp)}\")\n",
    "    print(f\"File CSV generato: {output_path}\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "print(\"Elaborazione completata.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade Republic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trovati 1 file PDF contenenti 'TradeRepublic':\n",
      "  - TradeRepublic_October.pdf\n",
      "\n",
      "Inizio elaborazione...\n",
      "\n",
      "======================================================================\n",
      "FILE: TradeRepublic_October.pdf\n",
      "----------------------------------------------------------------------\n",
      "Transazioni estratte: 99\n",
      "File CSV generato: C:\\Users\\loren\\OneDrive\\Desktop\\Areas\\Finanza\\TradeRepublic_October.csv\n",
      "======================================================================\n",
      "\n",
      "Elaborazione completata.\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2025\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pypdf import PdfReader\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# === Funzione per pulire la descrizione ===\n",
    "def pulisci_descrizione(testo):\n",
    "    if not isinstance(testo, str):\n",
    "        return \"\"\n",
    "\n",
    "    testo = testo.strip()\n",
    "\n",
    "    # Bonifico in entrata: \"BONIFICO A VOSTRO FAVORE ... DA:\"\n",
    "    if \"BONIFICO A VOSTRO FAVORE\" in testo.upper() and \"DA:\" in testo.upper():\n",
    "        m = re.search(r\"DA:\\s*([^,]+)\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(1).strip()\n",
    "\n",
    "    # Bonifico in uscita: \"BONIFICO SEPA A:\"\n",
    "    if \"BONIFICO SEPA A:\" in testo.upper():\n",
    "        m = re.search(r\"A:\\s*([^P]+)\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(1).strip()\n",
    "\n",
    "    # Pagamenti con carta, contactless, Apple Pay, ecc.\n",
    "    if \"PAGAMENTO\" in testo.upper():\n",
    "        m = re.search(r\"EUR [\\d,.]+\\s*(.*)\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            beneficiario = m.group(1)\n",
    "            beneficiario = re.sub(r\"\\b\\d+\\b\", \"\", beneficiario)  # rimuove numeri\n",
    "            beneficiario = re.sub(r\"\\s{2,}\", \" \", beneficiario)   # rimuove spazi doppi\n",
    "            return beneficiario.strip()\n",
    "\n",
    "    # Addebiti SEPA o PayPal\n",
    "    if \"SEPA\" in testo.upper() or \"PAYPAL\" in testo.upper():\n",
    "        m = re.search(r\"PayPal[^\\s,]*\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(0).strip()\n",
    "        m = re.search(r\"da\\s+([A-Za-z\\s\\.&]+)\\s+mandato\", testo, re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(1).strip()\n",
    "\n",
    "    # Fallback: testo pulito senza simboli eccessivi\n",
    "    testo = re.sub(r\"\\s{2,}\", \" \", testo)\n",
    "    return testo.strip()\n",
    "\n",
    "\n",
    "def clean_page_lines(page_lines):\n",
    "    header_re = re.compile(r\"DATA\\s+TIPO\\s+DESCRIZIONE\\s+IN\\s+ENTRATA\\s+IN\\s+USCITA\\s+SALDO\", re.IGNORECASE)\n",
    "    euro_re = re.compile(r\"€\")\n",
    "\n",
    "    # 1. Trova tutti gli indici delle intestazioni\n",
    "    header_indices = [i for i, l in enumerate(page_lines) if header_re.search(l)]\n",
    "    if not header_indices:\n",
    "        return page_lines[:]  # nessuna intestazione trovata\n",
    "\n",
    "    # 2. Elimina righe prima della prima intestazione\n",
    "    first_header = header_indices[0]\n",
    "    lines = page_lines[first_header:]\n",
    "    rel_header_indices = [i - first_header for i in header_indices if i >= first_header]\n",
    "    n = len(lines)\n",
    "\n",
    "    cleaned = []\n",
    "    pos = 0\n",
    "\n",
    "    for h_idx, header_pos in enumerate(rel_header_indices):\n",
    "        # Definisci il blocco corrente (tra intestazioni)\n",
    "        next_header = rel_header_indices[h_idx + 1] if h_idx + 1 < len(rel_header_indices) else n\n",
    "\n",
    "        # Trova l’ultima riga con \"€\" prima della prossima intestazione\n",
    "        last_euro = None\n",
    "        for i in range(header_pos + 1, next_header):\n",
    "            if euro_re.search(lines[i]):\n",
    "                last_euro = i\n",
    "\n",
    "        # Mantieni solo le righe dopo l’intestazione e fino all’ultima con €\n",
    "        if last_euro is not None:\n",
    "            cleaned.extend(lines[header_pos + 1:last_euro + 1])\n",
    "\n",
    "    # 3. Dopo l’ultima intestazione, controlla eventuali righe residue con “€” (es. fine documento)\n",
    "    if rel_header_indices and rel_header_indices[-1] < n:\n",
    "        tail_start = rel_header_indices[-1]\n",
    "        last_euro = None\n",
    "        for i in range(tail_start + 1, n):\n",
    "            if euro_re.search(lines[i]):\n",
    "                last_euro = i\n",
    "        if last_euro is not None:\n",
    "            cleaned.extend(lines[tail_start + 1:last_euro + 1])\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "def parse_transactions(lines):\n",
    "    \"\"\"\n",
    "    lines: lista di stringhe (righe estratte dal PDF)\n",
    "    restituisce: DataFrame con colonne ['Data','Beneficiario','Importo','Saldo']\n",
    "    \"\"\"\n",
    "    # pattern\n",
    "    day_pattern = re.compile(r\"^\\d{1,2}$\")\n",
    "    month_pattern = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]+$\")   # mese (es. mag, nov, Aprile)\n",
    "    day_month_pattern = re.compile(r\"^\\d{1,2}\\s+[A-Za-zÀ-ÖØ-öø-ÿ]+$\")  # \"01 mag\"\n",
    "    year_pattern = re.compile(r\"^\\d{4}$\")\n",
    "    header_pattern = re.compile(r\"DATA\\s+TIPO\\s+DESCRIZIONE\\s+IN\\s+ENTRATA\\s+IN\\s+USCITA\\s+SALDO\", re.IGNORECASE)\n",
    "    panorama_pattern = re.compile(r\"PANORAMICA\", re.IGNORECASE)\n",
    "    euro_pattern = re.compile(r\"([\\d\\.\\,]+)\\s*€\")\n",
    "\n",
    "    records = []\n",
    "    i = 0\n",
    "    n = len(lines)\n",
    "\n",
    "    # opzionale: elimina tutto prima della prima header se presente\n",
    "    first_header_idx = next((idx for idx, l in enumerate(lines) if header_pattern.search(l)), None)\n",
    "    if first_header_idx is not None:\n",
    "        lines = lines[first_header_idx:] \n",
    "        n = len(lines)\n",
    "\n",
    "    while i < n:\n",
    "        # prova a riconoscere una data a partire da lines[i]\n",
    "        date_str = None\n",
    "        consumed = 0\n",
    "\n",
    "        s = lines[i].strip()\n",
    "        # caso 1: \"01 mag\" in una riga\n",
    "        if day_month_pattern.match(s):\n",
    "            date_str = s\n",
    "            consumed = 1\n",
    "        else:\n",
    "            # caso 2: giorno su una riga, mese su successiva, anno su successiva (o mese+anno)\n",
    "            if day_pattern.match(s) and i+1 < n and month_pattern.match(lines[i+1].strip()):\n",
    "                # giorno + mese\n",
    "                day = s\n",
    "                month = lines[i+1].strip()\n",
    "                # anno possibile\n",
    "                if i+2 < n and year_pattern.match(lines[i+2].strip()):\n",
    "                    year = lines[i+2].strip()\n",
    "                    date_str = f\"{day} {month} {year}\"\n",
    "                    consumed = 3\n",
    "                else:\n",
    "                    date_str = f\"{day} {month}\"\n",
    "                    consumed = 2\n",
    "            # caso 3: giorno e anno separate (meno probabile), oppure riga già \"01 apr 2025\" (coperto da day_month_pattern? no)\n",
    "            elif day_pattern.match(s) and i+1 < n and year_pattern.match(lines[i+1].strip()):\n",
    "                date_str = f\"{s} {lines[i+1].strip()}\"\n",
    "                consumed = 2\n",
    "            # caso 4: riga già \"01 apr 2025\" (giorno mese anno in una riga)\n",
    "            elif re.match(r\"^\\d{1,2}\\s+[A-Za-zÀ-ÖØ-öø-ÿ]+\\s+\\d{4}$\", s):\n",
    "                date_str = s\n",
    "                consumed = 1\n",
    "            # caso 5: riga tipo \"01 apr\" / next line contains \"2025 Trasferimento...\" -> treat as date if next starts with year\n",
    "            elif day_month_pattern.match(s) and i+1 < n and year_pattern.match(lines[i+1].strip().split()[0]):\n",
    "                date_str = s + \" \" + lines[i+1].strip().split()[0]\n",
    "                consumed = 2\n",
    "\n",
    "        if date_str is None:\n",
    "            # non è una data: avanza\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # avanzare oltre le righe consumate della data\n",
    "        i += consumed\n",
    "        if i >= n:\n",
    "            break\n",
    "\n",
    "        # ora raggruppa le righe fino a raggiungere il saldo (ultimo € della transazione)\n",
    "        full_parts = []\n",
    "        last_euro_count = 0\n",
    "        safety_counter = 0\n",
    "        while i < n:\n",
    "            line = lines[i].strip()\n",
    "            # fermati se incontri una header o PANORAMICA (è probabile che la transazione sia incompleta)\n",
    "            if header_pattern.search(line) or panorama_pattern.search(line):\n",
    "                break\n",
    "\n",
    "            full_parts.append(line)\n",
    "            last_euro_count = sum(1 for part in full_parts if \"€\" in part)\n",
    "            i += 1\n",
    "            safety_counter += 1\n",
    "\n",
    "            # condizione di stop robusta:\n",
    "            # - se abbiamo almeno un '€' e la riga corrente contiene '€' e la riga successiva è header/date/PANORAMICA, oppure\n",
    "            # - se abbiamo >=2 simboli € (importo + saldo),\n",
    "            # - oppure se raggiungiamo la fine\n",
    "            next_line = lines[i].strip() if i < n else \"\"\n",
    "            if last_euro_count >= 2:\n",
    "                break\n",
    "            if \"€\" in full_parts[-1] and ( header_pattern.search(next_line) or panorama_pattern.search(next_line) or day_pattern.match(next_line) or day_month_pattern.match(next_line) ):\n",
    "                # probabilmente saldo in questa riga\n",
    "                break\n",
    "\n",
    "            # safety: non lasciare mai loop infinito\n",
    "            if safety_counter > 2000:\n",
    "                break\n",
    "\n",
    "        # costruisci la descrizione completa\n",
    "        full_desc = \" \".join([p for p in full_parts if p])\n",
    "        # estrai tutti gli importi trovati in ordine\n",
    "        euro_matches = euro_pattern.findall(full_desc)\n",
    "\n",
    "        # normalizza importo e saldo (primo e ultimo match se disponibili)\n",
    "        amount = None\n",
    "        balance = None\n",
    "        if euro_matches:\n",
    "            if len(euro_matches) == 1:\n",
    "                # potrebbe essere solo importo (o solo saldo): assumiamo importo e nessun saldo\n",
    "                amount = euro_matches[0].replace('.', '').replace(',', '.')\n",
    "                balance = None\n",
    "            else:\n",
    "                amount = euro_matches[0].replace('.', '').replace(',', '.')\n",
    "                balance = euro_matches[-1].replace('.', '').replace(',', '.')\n",
    "\n",
    "        # beneficiary: la descrizione senza gli importi\n",
    "        beneficiary = euro_pattern.sub(\"\", full_desc).strip()\n",
    "        # se la descrizione inizia con un anno o verbo ripulire eventuale anno residuo\n",
    "        beneficiary = re.sub(r\"^\\d{4}\\b\", \"\", beneficiary).strip()\n",
    "\n",
    "        # salva record\n",
    "        try:\n",
    "            amount_f = float(amount) if amount is not None else None\n",
    "        except:\n",
    "            amount_f = None\n",
    "        try:\n",
    "            balance_f = float(balance) if balance is not None else None\n",
    "        except:\n",
    "            balance_f = None\n",
    "\n",
    "        records.append({\n",
    "            \"Data\": date_str,\n",
    "            \"Beneficiario\": beneficiary,\n",
    "            \"Importo\": amount_f,\n",
    "            \"Saldo\": balance_f\n",
    "        })\n",
    "\n",
    "    # crea DataFrame\n",
    "    df = pd.DataFrame(records, columns=[\"Data\", \"Beneficiario\", \"Importo\", \"Saldo\"])\n",
    "    return df\n",
    "\n",
    "MONTHS_IT = {\n",
    "    \"gen\": \"january\",\n",
    "    \"feb\": \"february\",\n",
    "    \"mar\": \"march\",\n",
    "    \"apr\": \"april\",\n",
    "    \"mag\": \"may\",\n",
    "    \"giu\": \"june\",\n",
    "    \"lug\": \"july\",\n",
    "    \"ago\": \"august\",\n",
    "    \"set\": \"september\",\n",
    "    \"ott\": \"october\",\n",
    "    \"nov\": \"november\",\n",
    "    \"dic\": \"december\",\n",
    "}\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    \"\"\"\n",
    "    Converte 'dd mmm' o 'dd mmm YYYY' con mesi italiani\n",
    "    nel formato 'mm/dd/YYYY'. Aggiunge 2025 se l'anno manca.\n",
    "    \"\"\"\n",
    "    if not isinstance(date_str, str):\n",
    "        return None\n",
    "\n",
    "    parts = date_str.strip().split()\n",
    "\n",
    "    if len(parts) == 2:\n",
    "        day, month = parts\n",
    "        year = \"2025\"\n",
    "    elif len(parts) == 3:\n",
    "        day, month, year = parts\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    month = month.lower()\n",
    "\n",
    "    # normalizza mese breve → mese esteso italiano\n",
    "    if month in MONTHS_IT:\n",
    "        month = MONTHS_IT[month]\n",
    "\n",
    "    # parsing mesi italiani\n",
    "    try:\n",
    "        dt = datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    return dt.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "def normalize_date_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Applica normalize_date a tutte le celle della colonna.\n",
    "    Restituisce il DataFrame con la colonna convertita.\n",
    "    \"\"\"\n",
    "    df[column_name] = df[column_name].apply(normalize_date)\n",
    "    return df\n",
    "\n",
    "# Directory contenente i PDF\n",
    "pdf_dir = r\"C:\\Users\\loren\\OneDrive\\Desktop\\Areas\\Finanza\"\n",
    "pdf_files = [\n",
    "    f for f in os.listdir(pdf_dir)\n",
    "    if f.lower().endswith(\".pdf\") and \"traderepublic\" in f.lower()\n",
    "]\n",
    "\n",
    "# Regex e funzioni di supporto\n",
    "regex_list = [r\"\\b\\d\\d\\s\", r\"\\b\\d\\s\", r\"\\b\\d\"]\n",
    "\n",
    "def remove_elements_at_indices(test_list, idx_list):\n",
    "    if not idx_list:\n",
    "        return test_list\n",
    "    first_idx = idx_list[0]\n",
    "    rest_of_indices = idx_list[1:]\n",
    "    sub_list = remove_elements_at_indices(test_list, rest_of_indices)\n",
    "    sub_list.pop(first_idx)\n",
    "    return sub_list\n",
    "\n",
    "def clean_beneficiario(df, column=\"Beneficiario\"):\n",
    "    \"\"\"\n",
    "    Rimuove dal campo Beneficiario prefissi indesiderati.\n",
    "    Pulizia case-insensitive, elimina spazi extra.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r\"^transazione con carta\\s*\",\n",
    "        r\"^pagamento degli interessi\\s*\",\n",
    "        r\"^premio\\s*\",\n",
    "        r\"^commercio\\s*\",\n",
    "        r\"^redditi\\s*\",\n",
    "    ]\n",
    "\n",
    "    combined = re.compile(\"|\".join(patterns), flags=re.IGNORECASE)\n",
    "\n",
    "    df[column] = (\n",
    "        df[column]\n",
    "        .str.replace(combined, \"\", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def apply_import_sign(df, import_col=\"Importo\", saldo_col=\"Saldo\"):\n",
    "    \"\"\"\n",
    "    Determina il segno degli importi confrontando il saldo precedente.\n",
    "    Se saldo_prev + importo == saldo_corr → importo positivo.\n",
    "    Altrimenti → negativo.\n",
    "    Il segno viene aggiunto come stringa: '+...' oppure '-...'.\n",
    "    \"\"\"\n",
    "    \n",
    "    saldi = df[saldo_col].astype(float).values\n",
    "    importi = df[import_col].astype(float).values\n",
    "\n",
    "    signed_values = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            # nessun saldo precedente: non si può dedurre il segno\n",
    "            signed_values.append(f\"{importi[i]:.2f}\")\n",
    "            continue\n",
    "        \n",
    "        saldo_prev = saldi[i-1]\n",
    "        saldo_curr = saldi[i]\n",
    "        imp = importi[i]\n",
    "\n",
    "        # confronto con tolleranza per floating point\n",
    "        if abs((saldo_prev + imp) - saldo_curr) < 0.0001:\n",
    "            sign = \"+\"\n",
    "        else:\n",
    "            sign = \"-\"\n",
    "\n",
    "        signed_values.append(f\"{sign}{imp:.2f}\")\n",
    "\n",
    "    df[import_col] = signed_values\n",
    "    return df\n",
    "\n",
    "# Inizio elaborazione\n",
    "print(f\"\\nTrovati {len(pdf_files)} file PDF contenenti 'TradeRepublic':\")\n",
    "for f in pdf_files:\n",
    "    print(f\"  - {f}\")\n",
    "print(\"\\nInizio elaborazione...\\n\")\n",
    "\n",
    "# Processamento PDF\n",
    "for file_name in pdf_files:\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"FILE: {file_name}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    df_temp = pd.DataFrame(columns=[\"Data\", \"Beneficiario\", \"Importo\"])\n",
    "    file_path = os.path.join(pdf_dir, file_name)\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    page_lines = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        lines = text.splitlines()\n",
    "        page_lines.extend(lines)\n",
    "\n",
    "    cleaned_lines = clean_page_lines(page_lines)\n",
    "\n",
    "    df_temp = parse_transactions(cleaned_lines)\n",
    "    df_temp = normalize_date_column(df_temp, \"Data\")\n",
    "    df_temp = clean_beneficiario(df_temp, column=\"Beneficiario\")\n",
    "    df_temp = apply_import_sign(df_temp)\n",
    "\n",
    "    # Salvataggio\n",
    "    output_path = os.path.join(pdf_dir, f\"{file_name[:-4]}.csv\")\n",
    "    df_temp.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Transazioni estratte: {len(df_temp)}\")\n",
    "    print(f\"File CSV generato: {output_path}\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "print(\"Elaborazione completata.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal-finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
